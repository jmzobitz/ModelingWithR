# Information Criteria

```{r echo=FALSE}
library(modelr)
```
Recall the key problem of _parameter estimation_, which can be generally stated as the following:

> Determine the set of parameters $\vec{\alpha}$ that minimize the difference between data $\vec{y}$ and the output of the function $f(\vec{x}, \vec{\alpha})$ and measured error $\vec{\sigma}$.


Let's say we have not just one model $f(\vec{x}, \vec{\alpha})$, but an alternative model for the data $\vec{y}$ that can be represented as $g(\vec{x}, \vec{\beta})$.  Between these two models ($f$ and $g$), how would we determine which one is ``best''?

Let's talk about a specific example.  When we did linear regression on the global temperature dataset, the quadratic and cubic models were approximately the same:

```{r,echo=FALSE,fig.width=5,fig.height=4}
regression_formula0 <-  globalTemp ~ 1 + yearSince1880 
regression_formula1 <-  globalTemp ~ 1 + yearSince1880 + I(yearSince1880^2) 
regression_formula2 <-  globalTemp ~ 1 + yearSince1880 + I(yearSince1880^2) + I(yearSince1880^3)
regression_formula3 <-  globalTemp ~ 1 + yearSince1880 + I(yearSince1880^2) + I(yearSince1880^3)+I(yearSince1880^4)
 fit0=lm(regression_formula0, data = global_temperature)
 fit1=lm(regression_formula1, data = global_temperature)
  fit2=lm(regression_formula2, data = global_temperature)
  fit3=lm(regression_formula3, data = global_temperature)
  
  smooth_data0 <- data.frame(x=global_temperature[[1]],y=predict(fit0))
  smooth_data1 <- data.frame(x=global_temperature[[1]],y=predict(fit1))
  smooth_data2 <- data.frame(x=global_temperature[[1]],y=predict(fit2))
  smooth_data3 <- data.frame(x=global_temperature[[1]],y=predict(fit3))
  
  ggplot(data=global_temperature,aes(x=yearSince1880,y=globalTemp)) +
    geom_point(color='black',size=2) +
    geom_line(data=smooth_data0,aes(x=x,y=y,color="0"),size=1.0,linetype=1)+
    geom_line(data=smooth_data1,aes(x=x,y=y,color="1"),size=1.0,linetype=2)+
    geom_line(data=smooth_data2,aes(x=x,y=y,color="2"),size=1.0,linetype=3)+
    geom_line(data=smooth_data2,aes(x=x,y=y,color="3"),size=1.0,linetype=4)+
    theme(plot.title = element_text(size=20),
          axis.title.x=element_text(size=20),
          axis.text.x=element_text(size=15),
          axis.text.y=element_text(size=15),
          axis.title.y=element_text(size=20)) +
   # stat_smooth(method = "lm", col = "black", formula = regression_formula) +
    labs(x = "Year Since 1880",y = "Temperature") +
    scale_color_manual(values=c("deeppink2","blue","darkolivegreen4","coral"),labels=c("Linear","Quadratic", "Cubic","Quartic"))


#plotRegression_Data(global_temperature,regression_formula)
```

The variation in the figure shows how different, but similar, the model results can be depending on the choice of regression function.  In some cases, the Log likelihood decreases (indicating a more likely model), with a smaller root mean square error.

Model  | Log Likelihood | RMSE
------------- | ------------- | -------------
Linear    | `r logLik(fit0)` | `r rmse(fit0,data=global_temperature)`
Quadratic    | `r logLik(fit1)` | `r rmse(fit1,data=global_temperature)`
Cubic        | `r logLik(fit2)` |`r rmse(fit2,data=global_temperature)`
Quartic        | `r logLik(fit3)` | `r rmse(fit3,data=global_temperature)`



Further model evaluation can be examined by the following:

- Compare the measured values of $\vec{y}$ to the modeled values of $\vec{y}$ in a 1:1 plot.  Does $g$ does a better job predicting $\vec{y}$ than $f$?
- Related to that, compare the likelihood function values of $f$ and $g$. We would favor the model that has the lower log likelihood.
- Compare the number of parameters in each model $f$ and $g$.  We would favor the model that has the fewest number of parameters.


 An alternative approach looks at the number of parameters in the model $f$ and $g$ and evaluates the tradeoff between model complexity (i.e. the number of parameters used) and the overall likelihood. 
 
 _Information criteria_ are used to assess the tradeoffs between model complexity and the number of parameters.  The goal of information criteria is to determine the _best approximating model_.

There are several types of information criteria, and this is a field of active study:

- The _Akaike Information Criteria_ (AIC) is the most commonly used: 

\begin{equation} 
AIC = -2 LL_{max} + 2 P
(\#eq:aic)
\end{equation}

- An alternative to the AIC is the __Bayesian Information Criterion__ (BIC)

\begin{equation}
BIC = -2 LL_{max} + P \ln (N),
(\#eq:bic)
\end{equation}
In  Equations \@ref(eq:aic) and \@ref(eq:bic) $N$ is the number of data points, $P$ is the number of estimated parameters, and $LL_{max}$ is
the log-likelihood for the parameter set that maximized the likelihood function.


In both cases, a lower value of the information criteria indicates greater support for the model from the data.  For both Equations \@ref(eq:aic) and \@ref(eq:bic) show the dependence on the log likelihood function and the number of parameters.

Let's evaluate how the AIC and BIC compare.  Let's try to work this with the dataset `global_temperature` in the `MAT369Code` library.  This dataset represents the average global temperature determined by NASA using local temperature data.  We will be working with these data to fit a function to data and parameters.


The function `informationCriteria` that generates a linear regression plot of the data and also returns the values of $N$, $P$, and  $LL_{max}$ you need to compute the AIC and the BIC.  The inputs to this command are very similar to `plotRegression_Data`:


```{r,fig.width=5,fig.height=4}
regression_formula <-  globalTemp ~ 1 + yearSince1880 
informationCriteria(global_temperature,regression_formula)
```

We can also add the different AIC to our table, providing a more complete picture of the best approximating model:

Model  | AIC
------------- | ------------- 
Linear    | `r AIC(fit0)` 
Quadratic    | `r AIC(fit1)` 
Cubic        | `r AIC(fit2)` 
Quartic        | `r AIC(fit3)` 

These results show that the quadratic model is the better approximating model.

For you R purists, you could also use the function `AIC` or `BIC`, which would require you defining the linear model:

```{r}
fit <- lm(regression_formula,data=global_temperature)
AIC(fit)
BIC(fit)

```

## A few cautionary notes

- Information criteria a relative measures.  In a study it may be more helpful to report the change in the information criteria, or even a ratio.
- Information criteria are not cross-comparable across studies.  If you are pulling in a model from another study, it is helpful to re-calculate the information criteria.
- The $BIC$ was created to provide some tradeoffs between favoring a model that has the fewer number of data needed to estimate parameters.  Other information criteria examine the distribution of the likelihood function and parameters.


__The upshot:__ Information criteria are _one_ piece of evidence to help you to evaluate the best approximating model.  You should do additional investigation (parameter evaluation, model-data fits, forecast values) in order to help determine the best model.

\newpage

## Exercises
```{exercise}
In the previous section you examined two different models for the growth of a yeast species in population:
  
  \begin{align}
\mbox{Model 1: } & V = \frac{K}{1+e^{-a-bt}} \\
\mbox{Model 2: } & V= K + Ae^{-bt}
\end{align}

Apply the AIC and the BIC to evaluate which model is the best approximating model.
```

&nbsp;

```{r pesticide,engine='tikz',warning=FALSE,message=FALSE,echo=FALSE,fig.cap="Reaction schemes."}
\begin{center}

\tikzstyle{vspecies}=[rectangle,minimum size=0.5cm,draw=black]
\begin{tikzpicture}[auto, outer sep=1pt, node distance=1.5cm]

%% Model 1  Burnham Anderson
\node [vspecies] (A) {$W$} ;
\node [vspecies, right of = A] (B) {$P$} ;
\node [vspecies, below of = A] (C) {$F$} ;
\node [vspecies, above of = A,node distance = 1cm] (model) {\textbf{Model 1}};
\draw [->] ([yshift=3pt]A.east) --  node[above] {\small{$k_1$}} ([yshift=3pt]B.west) ;
\draw [->] ([yshift=-3pt]B.west) --  node[below] {\small{$k_2$}} ([yshift=-3pt]A.east) ;

\draw [->] ([xshift=0]A.south) --  node[left] {\small{$k_3$}} ([xshift=0pt]C.north) ;

%%% Model 2a  Burnham Anderson
\node [vspecies, right of = B, node distance = 1.75 cm] (A2) {$W$} ;
\node [vspecies, right of = A2] (B2) {$P$} ;
\node [vspecies, below of = A2] (C2) {$F$} ;
\node [vspecies, above of = A2,node distance = 1cm] (model2) {\textbf{Model 2a}};
\draw [->] ([yshift=3pt]A2.east) --  node[above] {\small{$k_1$}} ([yshift=3pt]B2.west) ;
\draw [->] ([yshift=-3pt]B2.west) --  node[below] {\small{$k_2$}} ([yshift=-3pt]A2.east) ;

\draw [->] ([xshift=-2pt]A2.south) --  node[left] {\small{$k_3$}} ([xshift=-2pt]C2.north) ;
\draw [<-] ([xshift=2pt]A2.south) --  node[right] {\small{$k_4$}} ([xshift=2pt]C2.north) ;


%%% Model 2b Burnham Anderson
\node [vspecies, right of = B2, node distance = 1.75 cm] (A3) {$W$} ;
\node [vspecies, right of = A3] (B3) {$P$} ;
\node [vspecies, below of = A3] (C3) {$F$} ;
\node [vspecies, below of = C3] (A3pr) {$W'$} ;
\node [vspecies, above of = A3,node distance = 1cm] (model3) {\textbf{Model 2b}};
\draw [->] ([yshift=3pt]A3.east) --  node[above] {\small{$k_1$}} ([yshift=3pt]B3.west) ;
\draw [->] ([yshift=-3pt]B3.west) --  node[below] {\small{$k_2$}} ([yshift=-3pt]A3.east) ;

\draw [->] ([xshift=0]A3.south) --  node[left] {\small{$k_3$}} ([xshift=0pt]C3.north) ;
\draw [->] ([xshift=0]C3.south) --  node[left] {\small{$k_4$}} ([xshift=0pt]A3pr.north) ;


%%% Model 3a Burnham Anderson
\node [vspecies, below of = C, node distance = 3 cm] (A4) {$W$} ;
\node [vspecies, right of = A4] (B4) {$P$} ;
\node [vspecies, below of = A4] (C4) {$F$} ;
\node [vspecies, below of = C4] (A4pr) {$W'$} ;
\node [vspecies, right of = A4pr] (B4pr) {$P'$} ;


\node [vspecies, above of = A4,node distance = 1cm] (model4) {\textbf{Model 3a}};
\draw [->] ([yshift=3pt]A4.east) --  node[above] {\small{$k_1$}} ([yshift=3pt]B4.west) ;
\draw [->] ([yshift=-3pt]B4.west) --  node[below] {\small{$k_2$}} ([yshift=-3pt]A4.east) ;

\draw [->] ([xshift=0]A4.south) --  node[left] {\small{$k_3$}} ([xshift=0pt]C4.north) ;

\draw [->] ([xshift=0]C4.south) --  node[left] {\small{$k_4$}} ([xshift=0pt]A4pr.north) ;

\draw [->] ([yshift=0pt]A4pr.east) --  node[above] {\small{$k_5$}} ([yshift=0pt]B4pr.west) ;




%%% Model 3b Burnham Anderson
\node [vspecies, right of = B4, node distance = 1.75 cm] (A5) {$W$} ;
\node [vspecies, right of = A5] (B5) {$P$} ;
\node [vspecies, below of = A5] (C5) {$F$} ;
\node [vspecies, below of = C5] (A5pr) {$W'$} ;
\node [vspecies, right of = A5pr] (B5pr) {$P'$} ;


\node [vspecies, above of = A5,node distance = 1cm] (model5) {\textbf{Model 3b}};
\draw [->] ([yshift=3pt]A5.east) --  node[above] {\small{$k_1$}} ([yshift=3pt]B5.west) ;
\draw [->] ([yshift=-3pt]B5.west) --  node[below] {\small{$k_2$}} ([yshift=-3pt]A5.east) ;

\draw [->] ([xshift=0]A5.south) --  node[left] {\small{$k_3$}} ([xshift=0pt]C5.north) ;

\draw [->] ([yshift=-3pt]B5pr.west) --  node[below] {\small{$k_6$}} ([yshift=-3pt]A5pr.east) ;
\draw [<-] ([yshift=3pt]B5pr.west) --  node[above] {\small{$k_5$}} ([yshift=3pt]A5pr.east) ;


\draw [->] ([xshift=0]C5.south) --  node[left] {\small{$k_4$}} ([xshift=0pt]A5pr.north) ;


%%% Model 4a Burnham Anderson
\node [vspecies, below of = A4pr, node distance = 2.25 cm] (A6) {$W$} ;
\node [vspecies, right of = A6] (B6) {$P$} ;
\node [vspecies, below of = A6] (C6) {$F$} ;
\node [vspecies, right of = C6] (C6pr) {$F'$} ;
\node [vspecies, below of = C6] (A6pr) {$W'$} ;
\node [vspecies, right of = A6pr] (B6pr) {$P'$} ;


\node [vspecies, above of = A6,node distance = 1cm] (model6) {\textbf{Model 4a}};


\draw [->] ([yshift=3pt]A6.east) --  node[above] {\small{$k_1$}} ([yshift=3pt]B6.west) ;
\draw [->] ([yshift=-3pt]B6.west) --  node[below] {\small{$k_2$}} ([yshift=-3pt]A6.east) ;


\draw [->] ([yshift=3pt]C6.east) --  node[above] {\small{$k_8$}} ([yshift=3pt]C6pr.west) ;
\draw [->] ([yshift=-3pt]C6pr.west) --  node[below] {\small{$k_9$}} ([yshift=-3pt]C6.east) ;

\draw [->] ([yshift=0pt]A6pr.east) --  node[above] {\small{$k_5$}} ([yshift=0pt]B6pr.west) ;

\draw [->] ([yshift=0pt]C6.south) --  node[left] {\small{$k_4$}} ([yshift=0pt]A6pr.north) ;


\draw [->] ([xshift=0]A6.south) --  node[left] {\small{$k_3$}} ([xshift=0pt]C6.north) ;

%%% Model 4b Burnham Anderson
\node [vspecies, right of = B6, node distance = 1.75 cm] (A7) {$W$} ;
\node [vspecies, right of = A7] (B7) {$P$} ;
\node [vspecies, below of = A7] (C7) {$F$} ;

\node [vspecies, below of = C7] (A7pr) {$W'$} ;
\node [vspecies, right of = A7pr] (B7pr) {$P'$} ;

\node [vspecies, above of = A7,node distance = 1cm] (model7) {\textbf{Model 4b}};
\draw [->] ([yshift=3pt]A7.east) --  node[above] {\small{$k_1$}} ([yshift=3pt]B7.west) ;
\draw [->] ([yshift=-3pt]B7.west) --  node[below] {\small{$k_2$}} ([yshift=-3pt]A7.east) ;

\draw [->] ([xshift=0]A7.south) --  node[left] {\small{$k_3$}} ([xshift=0pt]C7.north) ;

\draw [->] ([xshift=-3pt]C7.south) --  node[left] {\small{$k_4$}} ([xshift=-3pt]A7pr.north) ;
\draw [<-] ([xshift=3pt]C7.south) --  node[right] {\small{$k_7$}} ([xshift=3pt]A7pr.north) ;

\draw [->] ([xshift=0]A7pr.east) --  node[above] {\small{$k_5$}} ([xshift=0pt]B7pr.west) ;

\end{tikzpicture}
\end{center}


```



<!-- From Burnham and Anderson pg 135 of pdf -->
```{exercise}
You are tasked with the job of investigating the effect of a pesticide on water quality, in terms of its effects on the health of the plants and fish in the ecosystem.  Different models can be created that investigate the effect of the pesticide.  Different types of reaction schemes for this system are shown in Figure \@ref(fig:pesticide), where $F$ represents the amount of pesticide in the fish, $W$ the amount of pesticide in the water, and $S$ the amount of pesticide in the soil.  The prime (e.g. $F'$, $W'$, and $S'$ represent other bound forms of the respective state).  In all seven different models can be derived.

These models were applied to a dataset with 36 measurements of the water, fish, and plants. The table for the log-likelihood for each model is shown below:

Model  | Log Likelihood 
------------- | ------------- 
1    | -90.105  
2a    | -71.986 
2b       | -56.869 
3a        | -31.598 
3b    | -31.563 
4a       | -8.770 
4b    | -14.238 



\begin{enumerate}
\item Identify the number of parameters for each model.
\item Apply the AIC and the BIC to the data in the above table to determine which is the best approximating model.
\end{enumerate}

```



